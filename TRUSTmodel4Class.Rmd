---
title: "Trust Model"
date: "`r paste('Last edits on:',date(), sep=' ')`"
output: 
  html_document:
    toc: true
    number_sections: false
    toc_float: true
    df_print: paged
    code_folding: show
  pdf_document: default
  html_notebook: default
---

```{r preamble, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	background = "#ADD8E6",
	cache = TRUE,
	tidy = 'styler',
	class.source = "bg-warning",
	class.output = "bg-success",
	fig_caption = TRUE,
	digits = 3
)
```

```{r libraries, include=FALSE}
using<-function(...) {
    libs<-unlist(list(...))
    req<-unlist(lapply(libs,require,character.only=TRUE))
    need<-libs[req==FALSE]
    if(length(need)>0){ 
        install.packages(need)
        lapply(need,require,character.only=TRUE)
    }
}
using("tidyverse","ggplot2","psych","corrplot","DT","formatR","ggExtra","car","rethinking","rstan","dagitty")

round_df <- function(df, digits) {
  nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))
  df[,nums] <- round(df[,nums], digits = digits)
  (df)
}
```

# The Model to Test

I have in mind two models - one that represents trust as a latent variable that I will compute outside of my stan code and one that represents trust as an emergent variable.  Why treat them differently?  Good question.  There is a tension in the literature that posits trust to be either latent or emergent.  Instead of worrying about how to handle it in the class, I opted to do two models and compare them.  Why not?

## Model 1:  Trust as a latent variable

```{r TModel1}
Tdag1 <- dagitty('dag {"Beh Int" [outcome,pos="-0.272,-0.078"]
"SR Trust" [pos="-0.327,-0.077"]
GI [pos="-0.398,-0.082"]
Rel [pos="-0.402,-0.077"]
Trust [latent,pos="-0.367,-0.077"]
Unc [pos="-0.402,-0.072"]
"SR Trust" -> "Beh Int"
Trust -> "SR Trust"
Trust -> GI
Trust -> Rel
Trust -> Unc
}
')
plot(Tdag1)
impliedConditionalIndependencies(Tdag1)
```

## Model 2: Trust as an emergent variable

```{r TModel2}
Tdag2 <- dagitty('dag {"Beh Int" [outcome,pos="-0.272,-0.078"]
"SR Trust" [pos="-0.327,-0.077"]
GI [pos="-0.398,-0.082"]
Rel [pos="-0.402,-0.077"]
Trust [outcome,pos="-0.367,-0.077"]
Unc [pos="-0.402,-0.072"]
"SR Trust" -> "Beh Int"
Trust -> "SR Trust"
Trust <- GI
Trust <- Rel
Trust <- Unc
}
')
plot(Tdag2)
impliedConditionalIndependencies(Tdag2)
```

# The Data

I have over 8 studies of trust data; for this class, I will use only one study to make life simpler.  The data come from a fully crossed design whereby participants read vignettes and rated the vignettes based upon several facets and then were asked to rate how much they would trust the agent in the vignette.  Our aim was to better understand the factors that lead to people indicating trust.  

```{r TData}
Tdat <- read.csv("/home/pem725/GoogleDrive/00 Most Current Papers/Trust - MRES New Model/Data/dat5alll.csv",header=T)[,-1]
describe(Tdat)
```

So I have B for my DV and G, U1, R as my manifest indicators of trust (the construct) that lead to predicting B through T (self-reported trust).  The model seems complicated but it is not really.  For each model, I need to create new variables.

## Model 1 Data Management

```{r M1Data, warning=FALSE}
pcor1 <- cor(Tdat[,c(3,4,6)],use="complete.obs")
Tdat.lwcN <- nrow(Tdat[complete.cases(Tdat[,c(3,4,6)]),])
pc1 <- principal(pcor1,1,residuals=TRUE,n.obs=Tdat.lwcN, scores = TRUE)
pc1.wts <- as.data.frame(pc1$weights)
str(pc1.wts)
#pc1.wts
Tdat$tx3.pc1 <- pc1.wts$PC1[1]*scale(Tdat$G) + pc1.wts$PC1[2]*scale(Tdat$U1) + pc1.wts$PC1[3]*scale(Tdat$R)
ggplot(Tdat,aes(tx3.pc1)) + geom_histogram()
```

## Model 2 Data Management

```{r M2Data}


```



# The Stan Models

## Model 1

```{r Model1}

```

